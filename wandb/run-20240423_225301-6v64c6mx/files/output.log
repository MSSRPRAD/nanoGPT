
step 0: train loss 10.9047, val loss 10.9018
iter 0: loss 10.9018, time 991967.75ms, mfu -100.00%
iter 10: loss 10.6741, time 5797.99ms, mfu 0.05%
iter 20: loss 9.9913, time 6011.83ms, mfu 0.05%
iter 30: loss 9.0558, time 6114.76ms, mfu 0.05%
iter 40: loss 7.9290, time 5498.71ms, mfu 0.05%
iter 50: loss 7.3504, time 6064.64ms, mfu 0.05%
Traceback (most recent call last):
  File "/home/mpradyumna/Documents/GitHub/nanoGPT/train.py", line 305, in <module>
    scaler.scale(loss).backward()
  File "/home/mpradyumna/Documents/GitHub/nanoGPT/venv/lib64/python3.12/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/mpradyumna/Documents/GitHub/nanoGPT/venv/lib64/python3.12/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt