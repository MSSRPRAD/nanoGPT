2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Current SDK version is 0.16.6
2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Configure stats pid to 17843
2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Loading settings from /teamspace/studios/this_studio/.config/wandb/settings
2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Loading settings from /teamspace/studios/this_studio/nanoGPT/wandb/settings
2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-04-20 20:21:25,403 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program_abspath': '/teamspace/studios/this_studio/nanoGPT/train.py', 'program': '/teamspace/studios/this_studio/nanoGPT/train.py'}
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_init.py:_log_setup():521] Logging user logs to /teamspace/studios/this_studio/nanoGPT/wandb/run-20240420_202125-aqjgbvrm/logs/debug.log
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_init.py:_log_setup():522] Logging internal logs to /teamspace/studios/this_studio/nanoGPT/wandb/run-20240420_202125-aqjgbvrm/logs/debug-internal.log
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_init.py:init():561] calling init triggers
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_init.py:init():568] wandb.init called with sweep_config: {}
config: {'out_dir': 'out-circuits', 'eval_interval': 250, 'log_interval': 10, 'eval_iters': 200, 'eval_only': False, 'always_save_checkpoint': False, 'init_from': 'scratch', 'wandb_log': True, 'wandb_project': 'circuits', 'wandb_run_name': 'circuits-run', 'dataset': 'circuits', 'gradient_accumulation_steps': 1, 'batch_size': 24, 'block_size': 1000, 'n_layer': 1, 'n_head': 12, 'n_embd': 384, 'dropout': 0.2, 'bias': False, 'learning_rate': 0.001, 'max_iters': 5000, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.9, 'grad_clip': 1.0, 'decay_lr': True, 'warmup_iters': 100, 'lr_decay_iters': 5000, 'min_lr': 0.0001, 'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True}
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_init.py:init():611] starting backend
2024-04-20 20:21:25,404 INFO    MainThread:17843 [wandb_init.py:init():615] setting up manager
2024-04-20 20:21:25,405 INFO    MainThread:17843 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-04-20 20:21:25,406 INFO    MainThread:17843 [wandb_init.py:init():623] backend started and connected
2024-04-20 20:21:25,408 INFO    MainThread:17843 [wandb_init.py:init():715] updated telemetry
2024-04-20 20:21:25,426 INFO    MainThread:17843 [wandb_init.py:init():748] communicating run to backend with 90.0 second timeout
2024-04-20 20:21:25,624 INFO    MainThread:17843 [wandb_run.py:_on_init():2357] communicating current version
2024-04-20 20:21:25,652 INFO    MainThread:17843 [wandb_run.py:_on_init():2366] got version response 
2024-04-20 20:21:25,652 INFO    MainThread:17843 [wandb_init.py:init():799] starting run threads in backend
2024-04-20 20:21:28,709 INFO    MainThread:17843 [wandb_run.py:_console_start():2335] atexit reg
2024-04-20 20:21:28,709 INFO    MainThread:17843 [wandb_run.py:_redirect():2190] redirect: wrap_raw
2024-04-20 20:21:28,710 INFO    MainThread:17843 [wandb_run.py:_redirect():2255] Wrapping output streams.
2024-04-20 20:21:28,710 INFO    MainThread:17843 [wandb_run.py:_redirect():2280] Redirects installed.
2024-04-20 20:21:28,711 INFO    MainThread:17843 [wandb_init.py:init():842] run started, returning control to user process
2024-04-20 20:21:33,245 WARNING MsgRouterThr:17843 [router.py:message_loop():77] message_loop has been closed
